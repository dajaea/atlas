{"topic": "forecasting", "english_title": "Forecasting", "english": "Forecasting is the process of making predictions based on past and present data and most commonly by analysis of trends. A commonplace example might be estimation of some variable of interest at some specified future date. Prediction is a similar, but more general term. Both might refer to formal statistical methods employing time series, cross-sectional or longitudinal data, or alternatively to less formal judgmental methods. Usage can differ between areas of application: for example, in hydrology the terms \"forecast\" and \"forecasting\" are sometimes reserved for estimates of values at certain specific future times, while the term \"prediction\" is used for more general estimates, such as the number of times floods will occur over a long period.\nRisk and uncertainty are central to forecasting and prediction; it is generally considered good practice to indicate the degree of uncertainty attaching to forecasts. In any case, the data must be up to date in order for the forecast to be as accurate as possible. In some cases the data used to predict the variable of interest is itself forecast.\n\n\n== Categories of forecasting methods ==\n\n\n=== Qualitative vs. quantitative methods ===\nQualitative forecasting techniques are subjective, based on the opinion and judgment of consumers and experts; they are appropriate when past data are not available.\nThey are usually applied to intermediate- or long-range decisions. Examples of qualitative forecasting methods are informed opinion and judgment, the Delphi method, market research, and historical life-cycle analogy.\nQuantitative forecasting models are used to forecast future data as a function of past data. They are appropriate to use when past numerical data is available and when it is reasonable to assume that some of the patterns in the data are expected to continue into the future.\nThese methods are usually applied to short- or intermediate-range decisions. Examples of quantitative forecasting methods are last period demand, simple and weighted N-Period moving averages, simple exponential smoothing, poisson process model based forecasting  and multiplicative seasonal indexes. Previous research shows that different methods may lead to different level of forecasting accuracy. For example, GMDH neural network was found to have  better forecasting performance than the classical forecasting algorithms such as Single Exponential Smooth, Double Exponential Smooth, ARIMA and back-propagation neural network.\n\n\n=== Average approach ===\nIn this approach, the predictions of all future values are equal to the mean of the past data. This approach can be used with any sort of data where past data is available. In time series notation:\n\n  \n    \n      \n        \n          \n            \n              \n                y\n                ^\n              \n            \n          \n          \n            T\n            +\n            h\n            \n              |\n            \n            T\n          \n        \n        =\n        \n          \n            \n              y\n              \u00af\n            \n          \n        \n        =\n        (\n        \n          y\n          \n            1\n          \n        \n        +\n        .\n        .\n        .\n        +\n        \n          y\n          \n            T\n          \n        \n        )\n        \n          /\n        \n        T\n      \n    \n    {\\displaystyle {\\hat {y}}_{T+h|T}={\\bar {y}}=(y_{1}+...+y_{T})/T}\n   where \n  \n    \n      \n        \n          y\n          \n            1\n          \n        \n        ,\n        .\n        .\n        .\n        ,\n        \n          y\n          \n            T\n          \n        \n      \n    \n    {\\displaystyle y_{1},...,y_{T}}\n   is the past data.\nAlthough the time series notation has been used here, the average approach can also be used for cross-sectional data (when we are predicting unobserved values; values that are not included in the data set). Then, the prediction for unobserved values is the average of the observed values.\n\n\n=== Na\u00efve approach ===\nNa\u00efve forecasts are the most cost-effective forecasting model, and provide a benchmark against which more sophisticated models can be compared. This forecasting method is only suitable for time series data. Using the na\u00efve approach, forecasts are produced that are equal to the last observed value. This method works quite well for economic and financial time series, which often have patterns that are difficult to reliably and accurately predict. If the time series is believed to have seasonality, the seasonal na\u00efve approach may be more appropriate where the forecasts are equal to the value from last season. In time series notation:\n\n  \n    \n      \n        \n          \n            \n              \n                y\n                ^\n              \n            \n          \n          \n            T\n            +\n            h\n            \n              |\n            \n            T\n          \n        \n        =\n        \n          y\n          \n            T\n          \n        \n      \n    \n    {\\displaystyle {\\hat {y}}_{T+h|T}=y_{T}}\n  \n\n\n=== Drift method ===\nA variation on the na\u00efve method is to allow the forecasts to increase or decrease over time, where the amount of change over time (called the drift) is set to be the average change seen in the historical data. So the forecast for time \n  \n    \n      \n        T\n        +\n        h\n      \n    \n    {\\displaystyle T+h}\n   is given by\n\n  \n    \n      \n        \n          \n            \n              \n                y\n                ^\n              \n            \n          \n          \n            T\n            +\n            h\n            \n              |\n            \n            T\n          \n        \n        =\n        \n          y\n          \n            T\n          \n        \n        +\n        \n          \n            h\n            \n              T\n              \u2212\n              1\n            \n          \n        \n        \n          \u2211\n          \n            t\n            =\n            2\n          \n          \n            T\n          \n        \n        (\n        \n          y\n          \n            t\n          \n        \n        \u2212\n        \n          y\n          \n            t\n            \u2212\n            1\n          \n        \n        )\n        =\n        \n          y\n          \n            T\n          \n        \n        +\n        h\n        \n          (\n          \n            \n              \n                \n                  y\n                  \n                    T\n                  \n                \n                \u2212\n                \n                  y\n                  \n                    1\n                  \n                \n              \n              \n                T\n                \u2212\n                1\n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle {\\hat {y}}_{T+h|T}=y_{T}+{\\frac {h}{T-1}}\\sum _{t=2}^{T}(y_{t}-y_{t-1})=y_{T}+h\\left({\\frac {y_{T}-y_{1}}{T-1}}\\right).}\n    This is equivalent to drawing a line between the first and last observation, and extrapolating it into the future.\n\n\n=== Seasonal na\u00efve approach ===\nThe seasonal na\u00efve method accounts for seasonality by setting each prediction to be equal to the last observed value of the same season. For example, the prediction value for all subsequent months of April will be equal to the previous value observed for April. The forecast for time \n  \n    \n      \n        T\n        +\n        h\n      \n    \n    {\\displaystyle T+h}\n   is\n\n  \n    \n      \n        \n          \n            \n              \n                y\n                ^\n              \n            \n          \n          \n            T\n            +\n            h\n            \n              |\n            \n            T\n          \n        \n        =\n        \n          y\n          \n            T\n            +\n            h\n            \u2212\n            k\n            m\n          \n        \n      \n    \n    {\\displaystyle {\\hat {y}}_{T+h|T}=y_{T+h-km}}\n  where \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  =seasonal period and \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   is the smallest integer greater than \n  \n    \n      \n        (\n        h\n        \u2212\n        1\n        )\n        \n          /\n        \n        m\n      \n    \n    {\\displaystyle (h-1)/m}\n  .\nThe seasonal na\u00efve method is particularly useful for data that has a very high level of seasonality.\n\n\n=== Time series methods ===\nTime series methods use historical data as the basis of estimating future outcomes.\nThey are based on the assumption that past demand history is a good indicator of future demand.\n\nMoving average\nWeighted moving average\nExponential smoothing\nAutoregressive moving average (ARMA) (forecasts depend on past values of the variable being forecast and on past prediction errors)\nAutoregressive integrated moving average (ARIMA) (ARMA on the period-to-period change in the forecast variable)e.g. Box\u2013Jenkins\nSeasonal ARIMA or SARIMA or ARIMARCH,Extrapolation\nLinear prediction\nTrend estimation (predicting the variable as a linear or polynomial function of time)\nGrowth curve (statistics)\nRecurrent neural network\n\n\n=== Relational methods ===\nSome forecasting methods try to identify the underlying factors that might influence the variable that is being forecast. For example, including information about climate patterns might improve the ability of a model to predict umbrella sales. Forecasting models often take account of regular seasonal variations. In addition to climate, such variations can also be due to holidays and customs: for example, one might predict that sales of college football apparel will be higher during the football season than during the off season.Several informal methods used in causal forecasting do not rely solely on the output of mathematical algorithms, but instead use the judgment of the forecaster. Some forecasts take account of past relationships between variables: if one variable has, for example, been approximately linearly related to another for a long period of time, it may be appropriate to extrapolate such a relationship into the future, without necessarily understanding the reasons for the relationship.\nCausal methods include:\n\nRegression analysis includes a large group of methods for predicting future values of a variable using information about other variables. These methods include both parametric (linear or non-linear) and non-parametric techniques.\nAutoregressive moving average with exogenous inputs (ARMAX)Quantitative forecasting models are often judged against each other by comparing their in-sample or out-of-sample mean square error, although some researchers have advised against this. Different forecasting approaches have different levels of accuracy. For example, it was found in one context that GMDH has higher forecasting accuracy than traditional ARIMA \n\n\n=== Judgmental methods ===\nJudgmental forecasting methods incorporate intuitive judgement, opinions and subjective probability estimates. Judgmental forecasting is used in cases where there is lack of historical data or during completely new and unique market conditions.Judgmental methods include:\n\nComposite forecasts\nCooke's method\nDelphi method\nForecast by analogy\nScenario building\nStatistical surveys\nTechnology forecasting\n\n\n=== Artificial intelligence methods ===\nArtificial neural networks\nGroup method of data handling\nSupport vector machinesOften these are done today by specialized programs loosely labeled\n\nData mining\nMachine learning\nPattern recognition\n\n\n=== Geometric Extrapolation with error prediction ===\nCan be created with 3 points of a sequence and the \"moment\" or \"index\", this type of extrapolation have 100 % accuracy in predictions in a big percentage of known series database (OEIS).\n\n\n=== Other methods ===\nGranger causality\nSimulation\nPrediction market\nProbabilistic forecasting and Ensemble forecasting\n\n\n== Forecasting accuracy ==\nThe forecast error (also known as a residual) is the difference between the actual value and the forecast value for the corresponding period:\n\n  \n    \n      \n         \n        \n          E\n          \n            t\n          \n        \n        =\n        \n          Y\n          \n            t\n          \n        \n        \u2212\n        \n          F\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\ E_{t}=Y_{t}-F_{t}}\n  where E is the forecast error at period t, Y is the actual value at period t, and F is the forecast for period t.\nA good forecasting method will yield residuals that are uncorrelated. If there are correlations between residual values, then there is information left in the residuals which should be used in computing forecasts. This can be accomplished by computing the expected value of a residual as a function of the known past residuals, and adjusting the forecast by the amount by which this expected value differs from zero.\nA good forecasting method will also have zero mean. If the residuals have a mean other than zero, then the forecasts are biased and can be improved by adjusting the forecasting technique by an additive constant that equals the mean of the unadjusted residuals.\nMeasures of aggregate error:\n\n\n=== Scaled-dependent errors ===\nThe forecast error, E, is on the same scale as the data, as such, these accuracy measures are scale-dependent and cannot be used to make comparisons between series on different scales.\nMean absolute error (MAE) or mean absolute deviation (MAD): \n  \n    \n      \n         \n        M\n        A\n        E\n        =\n        M\n        A\n        D\n        =\n        \n          \n            \n              \n                \u2211\n                \n                  t\n                  =\n                  1\n                \n                \n                  N\n                \n              \n              \n                |\n              \n              \n                E\n                \n                  t\n                \n              \n              \n                |\n              \n            \n            N\n          \n        \n      \n    \n    {\\displaystyle \\ MAE=MAD={\\frac {\\sum _{t=1}^{N}|E_{t}|}{N}}}\n  \nMean squared error (MSE) or mean squared prediction error (MSPE): \n  \n    \n      \n         \n        M\n        S\n        E\n        =\n        M\n        S\n        P\n        E\n        =\n        \n          \n            \n              \n                \u2211\n                \n                  t\n                  =\n                  1\n                \n                \n                  N\n                \n              \n              \n                \n                  E\n                  \n                    t\n                  \n                  \n                    2\n                  \n                \n              \n            \n            N\n          \n        \n      \n    \n    {\\displaystyle \\ MSE=MSPE={\\frac {\\sum _{t=1}^{N}{E_{t}^{2}}}{N}}}\n  \nRoot mean squared error (RMSE): \n  \n    \n      \n         \n        R\n        M\n        S\n        E\n        =\n        \n          \n            \n              \n                \n                  \u2211\n                  \n                    t\n                    =\n                    1\n                  \n                  \n                    N\n                  \n                \n                \n                  \n                    E\n                    \n                      t\n                    \n                    \n                      2\n                    \n                  \n                \n              \n              N\n            \n          \n        \n      \n    \n    {\\displaystyle \\ RMSE={\\sqrt {\\frac {\\sum _{t=1}^{N}{E_{t}^{2}}}{N}}}}\n  \nAverage of Errors (E): \n  \n    \n      \n         \n        \n          \n            \n              E\n              \u00af\n            \n          \n        \n        =\n        \n          \n            \n              \n                \u2211\n                \n                  i\n                  =\n                  1\n                \n                \n                  N\n                \n              \n              \n                \n                  E\n                  \n                    i\n                  \n                \n              \n            \n            N\n          \n        \n      \n    \n    {\\displaystyle \\ {\\bar {E}}={\\frac {\\sum _{i=1}^{N}{E_{i}}}{N}}}\n  \n\n\n=== Percentage errors ===\nThese are more frequently used to compare forecast performance between different data sets because they are scale-independent. However, they have the disadvantage of being extremely large or undefined if Y is close to or equal to zero.\nMean absolute percentage error (MAPE): \n  \n    \n      \n         \n        M\n        A\n        P\n        E\n        =\n        100\n        \u2217\n        \n          \n            \n              \n                \u2211\n                \n                  t\n                  =\n                  1\n                \n                \n                  N\n                \n              \n              \n                |\n              \n              \n                \n                  \n                    E\n                    \n                      t\n                    \n                  \n                  \n                    Y\n                    \n                      t\n                    \n                  \n                \n              \n              \n                |\n              \n            \n            N\n          \n        \n      \n    \n    {\\displaystyle \\ MAPE=100*{\\frac {\\sum _{t=1}^{N}|{\\frac {E_{t}}{Y_{t}}}|}{N}}}\n  \nMean absolute percentage deviation (MAPD): \n  \n    \n      \n         \n        M\n        A\n        P\n        D\n        =\n        \n          \n            \n              \n                \u2211\n                \n                  t\n                  =\n                  1\n                \n                \n                  N\n                \n              \n              \n                |\n              \n              \n                E\n                \n                  t\n                \n              \n              \n                |\n              \n            \n            \n              \n                \u2211\n                \n                  t\n                  =\n                  1\n                \n                \n                  N\n                \n              \n              \n                |\n              \n              \n                Y\n                \n                  t\n                \n              \n              \n                |\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\ MAPD={\\frac {\\sum _{t=1}^{N}|E_{t}|}{\\sum _{t=1}^{N}|Y_{t}|}}}\n  \n\n\n=== Scaled errors ===\nHyndman and Koehler (2006) proposed using scaled errors as an alternative to percentage errors.\nMean absolute scaled error (MASE): \n  \n    \n      \n        M\n        A\n        S\n        E\n        =\n        \n          \n            \n              \n                \u2211\n                \n                  t\n                  =\n                  1\n                \n                \n                  N\n                \n              \n              \n                |\n              \n              \n                \n                  \n                    E\n                    \n                      t\n                    \n                  \n                  \n                    \n                      \n                        1\n                        \n                          N\n                          \u2212\n                          m\n                        \n                      \n                    \n                    \n                      \u2211\n                      \n                        t\n                        =\n                        m\n                        +\n                        1\n                      \n                      \n                        N\n                      \n                    \n                    \n                      |\n                    \n                    \n                      Y\n                      \n                        t\n                      \n                    \n                    \u2212\n                    \n                      Y\n                      \n                        t\n                        \u2212\n                        m\n                      \n                    \n                    \n                      |\n                    \n                  \n                \n              \n              \n                |\n              \n            \n            N\n          \n        \n      \n    \n    {\\displaystyle MASE={\\frac {\\sum _{t=1}^{N}|{\\frac {E_{t}}{{\\frac {1}{N-m}}\\sum _{t=m+1}^{N}|Y_{t}-Y_{t-m}|}}|}{N}}}\n  \nwhere m=seasonal period or 1 if non-seasonal\n\n\n=== Other measures ===\nForecast skill (SS): \n  \n    \n      \n         \n        S\n        S\n        =\n        1\n        \u2212\n        \n          \n            \n              M\n              S\n              \n                E\n                \n                  f\n                  o\n                  r\n                  e\n                  c\n                  a\n                  s\n                  t\n                \n              \n            \n            \n              M\n              S\n              \n                E\n                \n                  r\n                  e\n                  f\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\ SS=1-{\\frac {MSE_{forecast}}{MSE_{ref}}}}\n  \nBusiness forecasters and practitioners sometimes use different terminology. They refer to the PMAD as the MAPE, although they compute this as a volume weighted MAPE. For more information see Calculating demand forecast accuracy.\nWhen comparing the accuracy of different forecasting methods on a specific data set, the measures of aggregate error are compared with each other and the method that yields the lowest error is preferred.\n\n\n=== Training and test sets ===\nWhen evaluating the quality of forecasts, it is invalid to look at how well a model fits the historical data; the accuracy of forecasts can only be determined by considering how well a model performs on new data that were not used when fitting the model. When choosing models, it is common to use a portion of the available data for fitting, and use the rest of the data for testing the model, as was done in the above examples.\n\n\n=== Cross-validation ===\nCross-validation is a more sophisticated version of training a test set.\nFor cross-sectional data, one approach to cross-validation works as follows:\n\nSelect observation i for the test set, and use the remaining observations in the training set. Compute the error on the test observation.\nRepeat the above step for  i = 1,2,..., N where N is the total number of observations.\nCompute the forecast accuracy measures based on the errors obtained.This makes efficient use of the available data, as only one observation is omitted at each step\nFor time series data, the training set can only include observations prior to the test set. Therefore, no future observations can be used in constructing the forecast. Suppose k observations are needed to produce a reliable forecast; then the process works as follows:\n\nStarting with i=1, select the observation k + i  for the test set, and use the observations at times  1, 2, ..., k+i\u20131 to estimate the forecasting model. Compute the error on the forecast for k+i.\nRepeat the above step for i = 2,...,T\u2013k  where T is the total number of observations.\nCompute the forecast accuracy over all errors.This procedure is sometimes known as a \"rolling forecasting origin\" because the \"origin\" (k+i -1) at which the forecast is based rolls forward in time. Further, two-step-ahead or in general p-step-ahead forecasts can be computed by first forecasting the value immediately after the training set, then using this value with the training set values to forecast two periods ahead, etc.\nSee also\n\nCalculating demand forecast accuracy\nConsensus forecasts\nForecast error\nPredictability\nPrediction intervals, similar to confidence intervals\nReference class forecasting\n\n\n== Seasonality and cyclic behaviour ==\n\n\n=== Seasonality ===\n\nSeasonality is a characteristic of a time series in which the data experiences regular and predictable changes which recur every calendar year. Any predictable change or pattern in a time series that recurs or repeats over a one-year period can be said to be seasonal. It is common in many situations \u2013 such as grocery store or even in a Medical Examiner's office\u2014that the demand depends on the day of the week. In such situations, the forecasting procedure calculates the seasonal index of the \u201cseason\u201d \u2013 seven seasons, one for each day \u2013 which is the ratio of the average demand of that season (which is calculated by Moving Average or Exponential Smoothing using  historical data corresponding only to that season) to the  average demand across all seasons. An index higher than 1 indicates that demand is higher than average; an index less than 1 indicates that the demand is less than the average.\n\n\n=== Cyclic behaviour ===\nThe cyclic behaviour of data takes place when there are regular fluctuations in the data which usually last for an interval of at least two years, and when the length of the current cycle cannot be predetermined. Cyclic behavior is not to be confused with seasonal behavior. Seasonal fluctuations follow a consistent pattern each year so the period is always known. As an example, during the Christmas period, inventories of stores tend to increase in order to prepare for Christmas shoppers. As an example of cyclic behaviour, the population of a particular natural ecosystem will exhibit cyclic behaviour when the population decreases as its natural food source decreases, and once the population is low, the food source will recover and the population will start to increase again. Cyclic data cannot be accounted for using ordinary seasonal adjustment since it is not of fixed period.\n\n\n== Applications ==\nForecasting has applications in a wide range of fields where estimates of future conditions are useful. Not everything can be forecast reliably, if the factors that relate to what is being forecast are known and well understood and there is a significant amount of data that can be used very reliable forecasts can often be obtained. If this is not the case or if the actual outcome is affected by the forecasts, the reliability of the forecasts can be significantly lower.Climate change and increasing energy prices have led to the use of Egain Forecasting for buildings. This attempts to reduce the energy needed to heat the building, thus reducing the emission of greenhouse gases. Forecasting is used in customer demand planning in everyday business for manufacturing and distribution companies.\nWhile the veracity of predictions for actual stock returns are disputed through reference to the Efficient-market hypothesis, forecasting of broad economic trends is common. Such analysis is provided by both non-profit groups as well as by for-profit private institutions.Forecasting foreign exchange movements is typically achieved through a combination of chart and fundamental analysis. An essential difference between chart analysis and fundamental economic analysis is that chartists study only the price action of a market, whereas fundamentalists attempt to look to the reasons behind the action. Financial institutions assimilate the evidence provided by their fundamental and chartist researchers into one note to provide a final projection on the currency in question.Forecasting has also been used to predict the development of conflict situations. Forecasters perform research that uses empirical results to gauge the effectiveness of certain forecasting models. However research has shown that there is little difference between the accuracy of the forecasts of experts knowledgeable in the conflict situation and those by individuals who knew much less.Similarly, experts in some studies argue that role thinking does not contribute to the accuracy of the forecast. The discipline of demand planning, also sometimes referred to as supply chain forecasting, embraces both statistical forecasting and a consensus process. An important, albeit often ignored aspect of forecasting, is the relationship it holds with planning. Forecasting can be described as predicting what the future will look like, whereas planning predicts what the future should look like.\nThere is no single right forecasting method to use. Selection of a method should be based on your objectives and your conditions (data etc.). A good place to find a method, is by visiting a selection tree. An example of a selection tree can be found here.\nForecasting has application in many situations:\n\nSupply chain management - Forecasting can be used in supply chain management to ensure that the right product is at the right place at the right time. Accurate forecasting will help retailers reduce excess inventory and thus increase profit margin. Studies have shown that extrapolations are the least accurate, while company earnings forecasts are the most reliable. Accurate forecasting will also help them meet consumer demand.\nCustomer demand planning\nEconomic forecasting\nEarthquake prediction\nEgain forecasting\nFinance against risk of default via credit ratings and credit scores\nLand use forecasting\nPlayer and team performance in sports\nPolitical forecasting\nProduct forecasting\nSales forecasting\nTechnology forecasting\nTelecommunications forecasting\nTransport planning and Transportation forecasting\nWeather forecasting, Flood forecasting and Meteorology\n\n\n== Limitations ==\nLimitations pose barriers beyond which forecasting methods cannot reliably predict.\nThere are many events and values that cannot be forecast reliably. Events such as the roll of a die or the results of the lottery cannot be forecast because they are random events and there is no significant relationship in the data. When the factors that lead to what is being forecast are not known or well understood such as in stock and foreign exchange markets forecasts are often inaccurate or wrong as there is not enough data about everything that affects these markets for the forecasts to be reliable, in addition the outcomes of the forecasts of these markets change the behavior of those involved in the market further reducing forecast accuracy.The concept of \"self-destructing predictions\" concerns the way in which some predictions can undermine themselves by influencing social behavior. This is because \"predictors are part of the social context about which they are trying to make a prediction and may influence that context in the process\". For example, a forecast that a large percentage of a population will become HIV infected based on existing trends may cause more people to avoid risky behavior and thus reduce the HIV infection rate, invalidating the forecast (which might have remained correct if it had not been publicly known). Or, a prediction that cybersecurity will become a major issue may cause organizations to implement more security cybersecurity measures, thus limiting the issue.\n\n\n=== Performance limits of fluid dynamics equations ===\nAs proposed by Edward Lorenz in 1963, long range weather forecasts, those made at a range of two weeks or more, are impossible to definitively predict the state of the atmosphere, owing to the chaotic nature of the fluid dynamics equations involved.  Extremely small errors in the initial input, such as temperatures and winds, within numerical models double every five days.\n\n\n== See also ==\n\n\n== References ==\n\nArmstrong, J. Scott, ed. (2001). Principles of Forecasting: A Handbook for Researchers and Practitioners. Norwell, Massachusetts: Kluwer Academic Publishers. ISBN 978-0-7923-7930-0.\nEllis, Kimberly (2010). Production Planning and Inventory Control. McGraw-Hill. ISBN 978-0-412-03471-8.\nGeisser, Seymour (June 1993). Predictive Inference: An Introduction. Chapman & Hall, CRC Press. ISBN 978-0-390-87106-0.\nGilchrist, Warren (1976). Statistical Forecasting. London: John Wiley & Sons. ISBN 978-0-471-99403-9.\nHyndman, Rob J.; Koehler, Anne B. (October\u2013December 2006). \"Another look at measures of forecast accuracy\" (PDF). International Journal of Forecasting. 22 (4): 679\u2013688. CiteSeerX 10.1.1.154.9771. doi:10.1016/j.ijforecast.2006.03.001.\nMakridakis, Spyros; Wheelwrigt, Steven; Hyndman, Rob J. (1998). Forecasting: Methods and Applications. John Wiley & Sons. ISBN 978-0-471-53233-0.\nMalakooti, Behnam (February 2014). Operations and Production Systems with Multiple Objectives. John Wiley & Sons. ISBN 978-0-470-03732-4.\nKaligasidis, Angela Sasic; Taesler, Roger; Andersson, Cari; Nord, Margitta (August 2006). \"Upgraded weather forecast control of building heating systems\".  In Fazio, Paul (ed.). Research in Building Physics and Building Engineering. Taylor & Francis, CRC Press. pp. 951\u2013958. ISBN 978-0-415-41675-7.\nKress, George J.; Snyder, John (May 1994). Forecasting and Market Analysis Techniques: A Practical Approach. Quorum Books. ISBN 978-0-89930-835-7.\nRescher, Nicholas (1998). Predicting the Future: An Introduction to the Theory of Forecasting. State University of New York Press. ISBN 978-0-7914-3553-3.\nTaesler, Roger (1991). \"Climate and Building Energy Management\". Energy and Buildings. 15 (1\u20132): 599\u2013608. doi:10.1016/0378-7788(91)90028-2.\nTurchin, Peter (2007). \"Scientific Prediction in Historical Sociology: Ibn Khaldun meets Al Saud\". History & Mathematics: Historical Dynamics and Development of Complex Societies. Moscow: KomKniga. pp. 9\u201338. ISBN 978-5-484-01002-8.\nUS patent 6098893, Berglund, Ulf Stefan & Lundberg, Bjorn Henry, \"Comfort control system incorporating weather forecast data and a method for operating such a system\", issued August 8, 2000 .\n\n\n== External links ==\n Media related to Prediction at Wikimedia Commons\nForecasting Principles: \"Evidence-based forecasting\"\nInternational Institute of Forecasters\nIntroduction to Time series Analysis (Engineering Statistics Handbook) - A practical guide to Time series analysis and forecasting\nTime Series Analysis\nGlobal Forecasting with IFs\nEarthquake Electromagnetic Precursor Research\nForecasting Science and Theory of Forecasting"}